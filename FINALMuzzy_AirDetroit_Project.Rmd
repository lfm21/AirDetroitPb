---
output: 
  pdf_document:
    keep_tex: yes
    fig_caption: yes
    number_sections: yes
geometry: margin=2.54cm
title: How has the "Motor City" of Detroit, MI, area experienced a decrease in air
  particulate lead over time?
subtitle: https://github.com/lfm21/AirDetroitPb
author: Laurie F. Muzzy
abstract: Tetraethyl lead (TEL) was completely phased out of gasoline in 1995; air
  lead levels have decreased 98% from 1980 to 2014. In addition to dramatically decreased airborne lead concentrations, another indicator of progress in the reduction of
  airborne lead in the environment is the drop in children's blood lead levels over
  time. Since the late 1970s, average blood lead concentration for children aged 1
  to 5 have dropped significantly, from about 15 micrograms per deciliter (µg/dL)
  to less than 1 µg/dL. On September 16, 2016, EPA announced its decision to retain,
  without revision, the national ambient air quality standards (NAAQS) for lead of
  0.15 ug/m3, in terms of a 3-month average concentration. I would like to see how
  the Detroit, MI, area (known as Motor City) has experienced a decrease in air lead
  levels over time.
fontsize: 12pt
mainfont: Times New Roman
---

<Information in these brackets are used for annotating the RMarkdown file. They will not appear in the final version of the PDF document>

\newpage
\tableofcontents 
#DONT FORGET THIS
\newpage
\listoftables 
\newpage
\listoffigures 
\newpage

<Setup the global options for the R chunks in your document>

<Note: set up autoreferencing for figures and tables in your document>

```{r setup, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
#Set your working directory
setwd("~/Desktop/Envtl_Data_Analytics/AirDetroitPb")
# Load your packages
knitr::opts_chunk$set(echo = TRUE)
library(readr)
devtools::install_github("Nowosad/spDataLarge")
library(dplyr)
library(tidyverse)
library(tidyr)
library(tidyselect)
library(lubridate)
library(ggplot2)
library(viridis)
library(viridisLite)
library(gridExtra)
library(colorRamps)
library(lsmeans)
library(nlme)
library(multcompView)
library(trend)
library(corrplot)
library(xtable)
#install.packages("sf")
#install.packages("raster")
#install.packages("spData")
library(leaflet)
library(mapview)
library(sf)
library(spData)
library(knitr)
getwd()

# Set your ggplot theme
Pbtheme <- theme_minimal(base_size = 11) +
theme(axis.text = element_text(color = "dark gray"),
      legend.position = "bottom")
  
theme_set(Pbtheme)

```


# Research Question and Rationale
<Paragraph detailing the rationale for your analysis. What is the significant application and/or interest in this topic? Connect to environmental topic(s)/challenge(s).>

Children under 6 are extremely vulnerable to lead poisoning, the effects of which show up later in life, and cannot be remediated. Lead exposure and poisoning therefore has large public health, social, and economic ramifications. Tetraethyl lead (TEL) was an additive in gasoline for decades, but growing public health pressures in the United States caused it to be completely phased out of gasoline by 1995. With this reduction of lead in nearly all gasoline, air lead levels have decreased 98% from 1980 to 2014.  In 2016, the U.S. EPA announced revised national ambient air quality standards (NAAQS) for lead of 0.15 ug/m3, in terms of a 3-month average concentration. Despite this ridiculously low concentration standard, and the dramatic decrease in the past four decades, lead still persists in the environment. Lead in paint has been banned in the U.S., but certain airplanes are still permitted to use leaded fuel. My research is interested in what lead concentrations are still extant in the air, especially in a larger American cities, where automobiles are the most common mode of transportation.

<Paragraph detailing your research question(s) and goals. What do you want to find out? Include a sentence (or a few) on the dataset you are using to answer this question - just enough to give your reader an idea of where you are going with the analysis.>

How has the "Motor City" Detroit, MI, area experienced a decrease in air lead levels over time?**** Where in the city has lead in air been sampled?**** Are the sample sites in the city at sites where vulnerable populations could be exposed?
\newpage

# Dataset Information

<Information on how the dataset for this analysis were collected, the data contained in the dataset, and any important pieces of information that are relevant to your analyses. This section should contain much of same information as the README file for the dataset but formatted in a way that is more narrative.>

The files were downloaded from https://www.epa.gov/outdoor-air-quality-data/download-daily-data and accessed on 2019-04-04. The area is Detroit-Warren-Dearborn in Michigan, USA. Lead(Pb) in air has been monitored every 12 days, since 1981 in Detroit-Dearborn-Warren area; there is a gap in data collection in the early 2000s. Files in .csv format were downloaded for every year available, which was 1981 until 2018. All files were accessed as .csv files, and named EPAair_Pb_Detroit_YEAR.csv
Shapefiles of neighborhoods in the area were downloaded from michigan.gov.

<Add a table that summarizes your data structure. This table can be made in markdown text or inserted as a `kable` function in an R chunk. If the latter, do not include the code used to generate your table.>

Table of raw dataset of Detroit-Dearborn-Warren area from 2018, to show example of raw dataset.
```{r kable table of data structure, echo=FALSE}
Pb2018<- read.csv("EPA_Pb_data_Raw/EPA_Pb_Detroit2018_raw.csv")
Pb2018str <- head(Pb2018)
head(Pb2018)
str(Pb2018)
Pb2018.table <- kable(Pb2018, "markdown",align = "l", 
                            caption = "EPA Air Lead in Detroit, 1981-2018", 
                            escape = TRUE) 
Pb2018.table
```

\newpage

# Exploratory Data Analysis and Wrangling

<Include R chunks for 5+ lines of summary code (display code and output), 3+ exploratory graphs (display graphs only), and any wrangling you do to your dataset(s).> 

Read in all 37 datasets.
```{r read in all raw data files, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
Pb1981 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1981_raw.csv")
Pb1982 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1982_raw.csv")
Pb1983 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1983_raw.csv")
Pb1984 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1984_raw.csv")
Pb1985 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1985_raw.csv")
Pb1986 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1986_raw.csv")
Pb1987 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1987_raw.csv")
Pb1988 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1988_raw.csv")
Pb1989 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1989_raw.csv")
Pb1990 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1990_raw.csv")
Pb1991 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1991_raw.csv")
Pb1992 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1992_raw.csv")
Pb1993 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1993_raw.csv")
Pb1994 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1994_raw.csv")
Pb1995 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1995_raw.csv")
Pb1996 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1996_raw.csv")
Pb1997 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1997_raw.csv")
Pb1998 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1998_raw.csv")
Pb1999 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit1999_raw.csv")
Pb2000 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2000_raw.csv")
Pb2001 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2001_raw.csv")
Pb2002 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2002_raw.csv")
Pb2003 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2003_raw.csv")
Pb2004 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2004_raw.csv")
Pb2005 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2005_raw.csv")
Pb2006 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2006_raw.csv")
Pb2007 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2007_raw.csv")
Pb2008 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2008_raw.csv")
Pb2009 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2009_raw.csv")
Pb2010 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2010_raw.csv")
Pb2011 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2011_raw.csv")
Pb2012 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2012_raw.csv")
Pb2013 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2013_raw.csv")
Pb2014 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2014_raw.csv")
Pb2015 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2015_raw.csv")
Pb2016 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2016_raw.csv")
Pb2017 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2017_raw.csv")
Pb2018 <- read.csv("./EPA_Pb_data_raw/EPA_Pb_Detroit2018_raw.csv")
```

Combine all datasets using rbind.
```{r one large dataset of all years, echo=FALSE}
Pb1981to2018.gathered <- rbind(Pb1981, Pb1982, Pb1983, Pb1984, Pb1985,
                      Pb1986, Pb1987, Pb1988, Pb1989, Pb1990,
                      Pb1991, Pb1992, Pb1993, Pb1994, Pb1995,
                      Pb1996, Pb1997, Pb1998, Pb1999, Pb2000,
                      Pb2005, Pb2006, Pb2007, Pb2008, Pb2009,
                      Pb2010, Pb2011, Pb2012, Pb2013, Pb2014,
                      Pb2015, Pb2016, Pb2017, Pb2018) 
#write.csv(Pb1981to2018.gathered, row.names = FALSE, "./EPA_Pb_data_Processed/Pb1981to2018.gathered.csv")

```

Format date to Date class for gathered data frame. Convert coordinates into geometry (using crs = 4326 from http://gis-michigan.opendata.arcgis.com/datasets/D3::master-plan-neighborhoods-detroit).
Select only useful columns to tidy up dataset.

```{r make points data frame, and to make tidy data frame, echo=TRUE}
library(dplyr) 
#if raster pkg loaded after dplyr, R will default to raster's select function

Pb1981to2018.gathered$Date <- as.Date(Pb1981to2018.gathered$Date, format = "%m/%d/%Y")
class(Pb1981to2018.gathered$Daily.Mean.Pb.Concentration)

Pb1981to2018.sf <- st_as_sf(Pb1981to2018.gathered,
                                coords = c("SITE_LATITUDE", "SITE_LONGITUDE"),
                                crs = 4326)

#write.csv(Pb1981to2018.sf, row.names = FALSE, "./EPA_Pb_data_Processed/Pb1981to2018.sf.csv")

Pb1981to2018.tidy <- Pb1981to2018.sf %>% 
  select(Date, Site.ID, Daily.Mean.Pb.Concentration,
         UNITS, Site.Name, geometry) %>% 
  mutate(year = year(Date), month = month(Date))

#write.csv(Pb1981to2018.tidy, row.names = FALSE, "./EPA_Pb_data_Processed/Pb1981to2018.tidy.csv")

Pb1981to2018.tidy.df <- Pb1981to2018.gathered %>% 
  select(Date, Site.ID, Daily.Mean.Pb.Concentration,
         UNITS, Site.Name, SITE_LATITUDE, SITE_LONGITUDE) %>% 
  mutate(year = year(Date), month = month(Date))

#write.csv(Pb1981to2018.tidy.df, row.names = FALSE, "./EPA_Pb_data_Processed/Pb1981to2018.tidy.df.csv")
  
```

View the summaries of the datasets. The first dataset was from 1981, so I chose that one to examine the column names, dimensions, structure, and class type.
```{r 1 - summary of example 1981 dataframe, then of Pb1981to2018.tidy}
str(Pb1981)
colnames(Pb1981) 
class(Pb1981$Date)
head(Pb1981)
summary(Pb1981)
dim(Pb1981)

dim(Pb1981to2018.tidy)
colnames(Pb1981to2018.tidy)
```

```{r 2.1 - exploratory histogram to see Pb concentration, using 1981 and 2009 datasets}
#1981 samples...
ggplot(Pb1981) +
  geom_histogram(aes(x = Daily.Mean.Pb.Concentration), bins = 45) +
  labs(title = "Air Lead in Detroit, 1981")
#and 2009
ggplot(Pb2009) +
  geom_histogram(aes(x = Daily.Mean.Pb.Concentration), bins = 120) +
  labs(title = "Air Lead in Detroit, 2009")
```

```{r 2.2 - histogram to see Pb concentration in a more recent year}


```

```{r 2.3 - two largest datasets: SWHS and Dearborn school sites}

summary(Pb1981to2018.sf$Site.Name)

Pb.large.sets <- Pb1981to2018.sf %>%
  filter(Site.Name %in% c("Southwestern H.S.",
                          "PROPERTY OWNED BY DEARBORN PUBLIC SCHOOLS"))

Pb.Dear.SWHS.plot <- ggplot(Pb.large.sets, 
                            aes(x = Date, y = Daily.Mean.Pb.Concentration,
                                color = Site.Name)) +
  geom_point(alpha = 0.25) +
  scale_color_manual(values = c( "magenta", "orange")) +
  labs(x = "Date", y = "Lead concentration, ug/m3")

Pb.large.sets.plot <- 
  ggplot(Pb.large.sets, 
         aes(x = Daily.Mean.Pb.Concentration, color = Site.Name)) +
  geom_freqpoly(stat = "count", alpha = 0.5) +
  labs(x = "Lead concentration, ug/m3", y = "number of observations", 
       title = "Sites in Detroit w/ Largest Sample Size of Air Lead Data")

grid.arrange(Pb.Dear.SWHS.plot, Pb.large.sets.plot)
```

It would be good to see the difference between the 1980s and the 2010s in terms of air Pb levels, so I made a 1980s data frame and a 2010s dataframe. Then I converted the coordinate columns to geometry points so they can be plotted on a map; and added a month and year column in order to see if there's seasonal change.

```{r 3.1 - standardize Site Names}
class(Pb1981to2018.tidy.df$Site.Name)
Pb1981to2018.tidy.df$Site.Name <- as.character(Pb1981to2018.tidy.df$Site.Name)

Pb1981to2018.tidy.df$Site.Name[Pb1981to2018.tidy.df$Site.Name == "(site not labeled)"] <- "(site not specified)"
Pb1981to2018.tidy.df$Site.Name[Pb1981to2018.tidy.df$Site.Name == "PROPERTY OWNED BY DEARBORN PUBLIC SCHOOLS"] <- "Dearborn public schools sites" 
Pb1981to2018.tidy.df$Site.Name[Pb1981to2018.tidy.df$Site.Name == "NMH48217 NEW MT HERMAN CHURCH"] <- "New Mt. Herman Church" 
Pb1981to2018.tidy.df$Site.Name[Pb1981to2018.tidy.df$Site.Name == "DP4th - Detroit Police 4th Precinct"] <- "DPD, 4th Precinct" 
Pb1981to2018.tidy.df$Site.Name[Pb1981to2018.tidy.df$Site.Name == "Eliza Downwind"] <- "Eliza Howell Park"

PbSites <- ggplot(Pb1981to2018.tidy.df, aes(x = Site.Name, fill = Site.Name)) +
  geom_histogram(stat = "count") +
  labs(x = "Sample Sites") +
  theme(legend.position = "right", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
print(PbSites)

#write.csv(Pb1981to2018.tidy.df, row.names = FALSE, "./EPA_Pb_data_Processed/Pb1981to2018.tidy.df.csv")
```

```{r 3.2 - create 1980s and 2010s dataframes}
#1980s
Pb1980s.gath <- rbind(Pb1981, Pb1982, Pb1983, Pb1984, Pb1985, 
                 Pb1986, Pb1987, Pb1988, Pb1989, Pb1990)

Pb1980s.gath$Date <- as.Date(Pb1980s.gath$Date, format = "%m/%d/%Y") 

Pb1980s <- Pb1980s.gath %>% select(Date, Site.ID, Daily.Mean.Pb.Concentration,
         UNITS, Site.Name, SITE_LATITUDE, SITE_LONGITUDE) %>% 
  mutate(year = year(Date), month = month(Date)) %>% 
  st_as_sf(coords = c("SITE_LATITUDE", "SITE_LONGITUDE"),crs = 4326)

#write.csv(Pb1980s, row.names = FALSE, "./EPA_Pb_data_Processed/Pb1980s.csv")
  
#2010s
Pb2010s.gath <- rbind(Pb2010, Pb2011, Pb2012, Pb2013, Pb2014, 
                 Pb2015, Pb2016, Pb2017, Pb2018)

Pb2010s.gath$Date <- as.Date(Pb2010s.gath$Date, format = "%m/%d/%Y") 

Pb2010s <- Pb2010s.gath %>% select(Date, Site.ID, Daily.Mean.Pb.Concentration,
         UNITS, Site.Name, SITE_LATITUDE, SITE_LONGITUDE) %>% 
  mutate(year = year(Date), month = month(Date)) %>% 
  st_as_sf(coords = c("SITE_LATITUDE", "SITE_LONGITUDE"),crs = 4326)

#write.csv(Pb2010s, row.names = FALSE, "./EPA_Pb_data_Processed/Pb2010s.csv")
```

```{r 3.3 - show differences in mean Pb by months in early 80s vs. last year}
#early 1980s plot
Pb1982$Date <- as.Date(Pb1982$Date, format = "%m/%d/%Y")

Pb1982.month <- select(Pb1982, Date, Site.ID, Daily.Mean.Pb.Concentration, UNITS,
         Site.Name, SITE_LATITUDE, SITE_LONGITUDE) %>% 
  mutate(year = year(Date), month = month(Date))

Pb1982.plot <- ggplot(Pb1982.month, aes(x = month,y = Daily.Mean.Pb.Concentration,
                                  color = Site.ID)) +
  geom_point(alpha = 0.75) +
  scale_color_viridis_c(breaks = c(0, 0.15, 0.75, 3.0), 
                        "Mean Lead\nConcentration", direction = -1) +
  scale_y_log10() +
  theme(legend.position = "right") +
  labs(title = "Air Lead in Detroit, 1982")

#and a more recent year
Pb2018$Date <- as.Date(Pb2018$Date, format = "%m/%d/%Y")

Pb2018.month <- select(Pb2018, Date, Site.ID, Daily.Mean.Pb.Concentration, UNITS,
         Site.Name, SITE_LATITUDE, SITE_LONGITUDE) %>% 
  mutate(year = year(Date), month = month(Date))

Pb2018.plot <- ggplot(Pb2018.month, aes(x = month,y = Daily.Mean.Pb.Concentration,
                                  color = Site.ID)) +
  geom_point(alpha = 0.75) +
  scale_color_viridis_c(breaks = c(0, 0.15, 0.75, 3.0), 
                        "Mean Lead\nConcentration", direction = -1) +
  scale_y_log10() +
  theme(legend.position = "right") +
  labs(title = "Air Lead in Detroit, 2018")

library(gridExtra)
grid.arrange(Pb1982.plot, Pb2018.plot, newpage = TRUE)
```

<Include text sections to accompany these R chunks to explain the reasoning behind your workflow, and the rationale for your approach.>


\newpage

# Analysis
<Include R chunks for 3+ statistical tests (display code and output) and 3+ final visualization graphs (display graphs only).>

<Include text sections to accompany these R chunks to explain the reasoning behind your workflow, rationale for your approach, and the justification of meeting or failing to meet assumptions of tests.>

###Is there a normal distribution of Daily Mean Lead Concentration values in different decades? In different months? At different sites? 
A  Shapiro-Wilk test was done on a few separate datasets. The Shapiro test can only run between 3 and 5000, so the Pb1981to2018.gathered data frame is slightly too large. Instead I'll run Shapiro on one dataset from each decade that has a relatively high number of observations. T-tests were then done to determine if the mean was indeed lower than 1.0ug/m3.
For all of these years, the p-values were very low, so we can reject the null hypothesis, as the alternative is true: the mean air lead concentration in these years was less than 1.0ug/m3.
From 1984 to 1990, the mean Pb concentration was an order of magnitude lower;
```{r 4.1 -  Shapiro-Wilk test: normal distribution, echo=TRUE}
#look at dataset from the 1980s, the 90s, the 2000s, and then a more recent dataset
summary(Pb1984$Daily.Mean.Pb.Concentration)
shapiro.test(Pb1984$Daily.Mean.Pb.Concentration)
#W = 0.88254, p-value = 3.677e-10
t.test.1smpl.1984 <- t.test(Pb1984$Daily.Mean.Pb.Concentration,
                            mu = 50, alternative = "less")
t.test.1smpl.1984 # -Inf 0.2244882, mean of x 0.206

summary(Pb1990$Daily.Mean.Pb.Concentration)
shapiro.test(Pb1990$Daily.Mean.Pb.Concentration)
#W = 0.28426, p-value < 2.2e-16
t.test.1smpl.1990 <- t.test(Pb1990$Daily.Mean.Pb.Concentration,
                            mu = 50, alternative = "less")
t.test.1smpl.1990

summary(Pb2006$Daily.Mean.Pb.Concentration)
shapiro.test(Pb2006$Daily.Mean.Pb.Concentration)
#W = 0.10127, p-value < 2.2e-16
t.test.1smpl.2006 <- t.test(Pb2006$Daily.Mean.Pb.Concentration,
                            mu =50, alternative = "less")
t.test.1smpl.2006
shapiro.test(Pb2017$Daily.Mean.Pb.Concentration)
#W = 0.36213, p-value < 2.2e-16
t.test.1smpl.2017 <- t.test(Pb2017$Daily.Mean.Pb.Concentration,
                            mu = 50, alternative = "less")
t.test.1smpl.2017
```

A comparison of the largest datasets was done to determine how different the variance between them may be. 
First Shapiro-Wilk tests then an F test was performed. The result is that the variance between the two populations is different. From the graph, it seems like we don't have a normal distribution with these datasets, so we should proceed with tests that do not necessarily require normality.
```{r 4.2 two-way t-test on largest sample sets, echo=TRUE}
#statistical comparison of the 2 largest sample sets
shapiro.test(Pb.large.sets$Daily.Mean.Pb.Concentration
             [Pb.large.sets$Site.Name == "Southwestern H.S."])

shapiro.test(Pb.large.sets$Daily.Mean.Pb.Concentration
             [Pb.large.sets$Site.Name == 
                 "PROPERTY OWNED BY DEARBORN PUBLIC SCHOOLS"])

var.test(Pb.large.sets$Daily.Mean.Pb.Concentration ~
           Pb.large.sets$Site.Name)

lm.Pb.large.sets <- lm(Pb.large.sets$Daily.Mean.Pb.Concentration ~
                          Pb.large.sets$Site.Name)
summary(lm.Pb.large.sets)

```

Kruskal-Wallis tests was performed on the whole large gathered data frame (Pb1981to2018.points); the p-val was low, showing some significance of the hypothesis that Pb concentration is realted to site.
Then Kruskal was done on the data frame with the two largest sample sizes (Pb.large.sets). We see that there is a significant difference between the two groups in the largest datasets.
DO A TEST WITH DAILY MEAN AND MONTH/SEASONALITY
```{r 4.3 kruskal-wallis test - non parametric, then wilcoxon for post-hoc}
#for the whole gathered dataset
Pb1981to2018.kw <- kruskal.test(Pb1981to2018.tidy$Daily.Mean.Pb.Concentration ~
                Pb1981to2018.points$Site.ID)
Pb1981to2018.kw
Pb1981to2018.wilcox <- 
  wilcox.test(Pb1981to2018.points$Daily.Mean.Pb.Concentration,
              mu = 50, alternative = "less")
Pb1981to2018.wilcox

#for the two large datasets
Pb.large.sets.kw <- kruskal.test(Pb.large.sets$Daily.Mean.Pb.Concentration ~
                Pb.large.sets$Site.ID)
Pb.large.sets.kw
Pb.large.sets.wilcox <- 
  wilcox.test(Pb.large.sets$Daily.Mean.Pb.Concentration,
              mu = 50, alternative = "less")
Pb.large.sets.wilcox

```
ANCOVA and was run for the whole gathered dataset of Pb concentrations from the all the sites from 1981 to 2018 to determine the level of co-variance. The linear models explained about 31% of the covariance here.
```{r 4.4 ANCOVA, echo=TRUE}
#is there co-variance btwn date and site?
Pb1981to2018.ancova <- lm(data = Pb1981to2018.points, 
                          Daily.Mean.Pb.Concentration ~ Date + Site.ID)
summary(Pb1981to2018.ancova) 

#is there an interaction btwn date and site?
Pb1981to2018.interaction <- lm(data = Pb1981to2018.points, 
                               Daily.Mean.Pb.Concentration ~ Date * Site.ID)
summary(Pb1981to2018.interaction) #explains about 31% of the variance

```

```{r 4.5 ??? Mann Kendall test on large sample sets, look for changepoints}


```

##Data Visualization
Graph of potential seasonal change.
```{r 5.1 Seasonality graph, echo=FALSE}

Pb1981to2018.tidy$month <- as.character(Pb1981to2018.tidy$month)
class(Pb1981to2018.tidy$month)

Pb.seasonal <- ggplot(Pb1981to2018.tidy, 
                      aes(x = month, y = Daily.Mean.Pb.Concentration,
                              color = Daily.Mean.Pb.Concentration)) +
  geom_point(size = 1.5) +
  scale_color_viridis_c(breaks = c(0, 0.15, 0.75, 3.0), 
                        "Mean Lead\nConcentration", direction = -1) +
  labs(title = "Seasonality of Lead Concentrations in Air, Detroit, 1981-2018", caption = "current NAAQS is 0.15 ug/m3") +
  geom_smooth(method = glm, size = 0.5, color = "blue") +
  scale_x_discrete(name = "month of the year", 
                   limits = c("1","2","3","4","5","6",
                              "7","8","9","10","11","12")) +
  ylab(expression("Mean lead concentration, ug/m3")) +
  theme(legend.position = "right")
print(Pb.seasonal)
```

Graph of air lead levels at places where children could be most at risk (schools, parks, church). 
```{r 5.2 parks/schools childrisk graph , echo=FALSE}
#filter schools and parks and fix labels
Pb.childrisk <-  Pb1981to2018.tidy %>%
  filter(Site.Name %in% c("PROPERTY OWNED BY DEARBORN PUBLIC SCHOOLS", 
                          "Allen Park", "Eliza Downwind", "Southwestern H.S.", 
                          "NMH48217 NEW MT HERMAN CHURCH", "River Rouge"))

Pb.childrisk$Site.Name[Pb.childrisk$Site.Name
                       == "PROPERTY OWNED BY DEARBORN PUBLIC SCHOOLS"] <-
  "Dearborn Public Schools"
Pb.childrisk$Site.Name[Pb.childrisk$Site.Name
                       == "NMH48217 NEW MT HERMAN CHURCH"] <-
  "New Mt. Herman Church"
Pb.childrisk$Site.Name[Pb.childrisk$Site.Name == "Eliza Downwind"] <-
  "Eliza Howell Park"
Pb.childrisk$Site.Name[Pb.childrisk$Site.Name == "River Rouge"] <- 
  "River Rouge Park"

#plots
Pb.childrisk.plot <- ggplot(Pb.childrisk,
                            aes(x = year, y = Daily.Mean.Pb.Concentration)) +
  geom_point(aes(), size = 2, alpha = 0.25) +
  scale_color_viridis_d() +
  geom_smooth(aes(color = Site.Name), method = "glm",
              se = FALSE, size = 1.5, show.legend = TRUE) +
  scale_y_log10() +
  labs(title = "Air Lead in Detroit parks, 1981-2018",
       x = "Year", y = "Lead Concentration ug/m3") +
  theme(axis.line.x = element_line(color = "black"),
        legend.position = "right")
print(Pb.childrisk.plot)

Pb.childrisk.plot2 <- ggplot(Pb.childrisk,
                            aes(x = year, color = Site.Name)) +
  geom_histogram(aes(), bins = 500, size = 2.5) +
  scale_color_viridis_d() +
  scale_y_log10() +
  labs(title = "Sampling for Air Lead in Detroit parks, 1981-2018",
       x = "Year", y = "Number of Samples") +
  theme(axis.line.x = element_line(color = "black"),
        legend.position = "right")
print(Pb.childrisk.plot2)

grid.arrange(Pb.childrisk.plot, Pb.childrisk.plot2)
```

```{r 5.3 plot of Pb concn over time}
class(Pb1981to2018.tidy.df$Date)

Pb.overtime <- ggplot(Pb1981to2018.tidy.df, 
                      aes(x = Date, y = Daily.Mean.Pb.Concentration)) +
  geom_point(size = 0.5, alpha = 0.25) +
  #scale_y_log10() +
  geom_vline(xintercept = "1995-01-01", color = "blue", lty = 2) +
  scale_fill_manual(breaks = c("1980", "1985", "1990",
                               "1995", "2000", "2005", "2010", "2015")) +
  theme(legend.position = "bottom")
print(Pb.overtime)

```
\newpage

# Summary and Conclusions
<Summarize your major findings from your analyses. What conclusions do you draw from your findings? Make sure to apply this to a broader application for the research question you have answered.>



